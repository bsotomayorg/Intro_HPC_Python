{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mgzxn85UdDlq"
   },
   "source": [
    "# Section 4: Introduction to High-Performance Computing on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOT1hovjZJTM"
   },
   "source": [
    "## 4.1. What's a GPU?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7I1mIyWOXOt"
   },
   "source": [
    "![](imgs/slides_d2/065.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJwvQvLjIXpB"
   },
   "source": [
    "+ It comes from **G**raphics **P**rocessing **U**nit.\n",
    "+ Specialized processor dedicated to graphics processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd1qOCjoZbi9"
   },
   "source": [
    "## 4.2. Differences between CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODidwLZfZfZI"
   },
   "source": [
    "**CPU:** \n",
    "+ Multiple cores.\n",
    "+ Complex control logic.\n",
    "+ Optimized for serial operations.\n",
    "\n",
    "**GPU:** \n",
    "+ Many parallel executing units (ALUs).\n",
    "+ Best known use case: Graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBY4jRgcZzTL"
   },
   "source": [
    "## 4.3 Compute Unified Device Architecture (CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02fs-NOZZ6f5"
   },
   "source": [
    "### 4.3.1. What's CUDA?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zoljPgbOT6u"
   },
   "source": [
    "<img src=\"imgs/slides_d2/070.PNG\" width=\"70%\" height=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ks6L4AHoI6US"
   },
   "source": [
    "+ Cuda is a software layer that gives direct access to the GPU’s virtual instruction set and parallel computational elements to execute functions, called *kernels*.\n",
    "+ CUDA is indicated as a General-Purpose computing on GPUs (GPGPU).\n",
    "+ GPUs traditionally handle computations for computer graphics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLnmvf7RavdZ"
   },
   "source": [
    "### 4.3.2. CUDA's Program Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDkxnv0KOQOb"
   },
   "source": [
    "<img src=\"imgs/slides_d2/071.PNG\" width=\"75%\" height=\"75%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hiWbJkHa4U7"
   },
   "source": [
    "1. Load data on Host.\n",
    "2. Allocate device memory.\n",
    "3. Copy data from Host to Device.\n",
    "4. Execute divece *kernels* to process data.\n",
    "5. Copy results from Device to Host memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XjJJ5iKbRED"
   },
   "source": [
    "## 4.4. Parallel GPU computing with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVtRkkmnbvOf"
   },
   "source": [
    "### 4.4.1. Universal functions (`ufunc`)\n",
    "\n",
    "A universal function is a function that operates on `ndarrays` in an element-by-element fashion, supporting array broadcasting, type casting, and several other standard features. \n",
    "\n",
    "A `ufunc` is a \"vectorized\" wrapper for a function that takes a fixed number of specific inputs and produces a fixed number of specific outputs. \n",
    "\n",
    "(_Source: [Numpy Documentation](https://numpy.org/doc/stable/reference/ufuncs.html)_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVVnPlcZcYRM"
   },
   "source": [
    "#### 4.4.1.1. Example: My first vectorized function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ggpWB7GcfvL"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrQNce9nbUlj"
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "num_points = int(1e6) # 1 million of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnLINLgdckkg"
   },
   "outputs": [],
   "source": [
    "@vectorize\n",
    "def cpu_sqrt(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MKax31wcmnD"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float32(float32)'], target='cuda')\n",
    "def gpu_sqrt(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPr0t0XodN0N"
   },
   "source": [
    "#### 4.4.1.2. Allowing multiple signatures in vectorized functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJl5wJqiK9Jz"
   },
   "source": [
    "Numba's vectorized functions can allow more than one data type as input. In that case, we will need to add another signature as the input parameter of the vectorize decorator.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfSIatVMdQ9H"
   },
   "outputs": [],
   "source": [
    "@vectorize(['int32(int32, int32)', 'float64(float64, float64)'])\n",
    "def my_ufunc(x, y):\n",
    "    return x+y+math.sqrt(x*math.cos(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H1miYPxeoxs"
   },
   "outputs": [],
   "source": [
    "@vectorize(['int32(int32, int32)', 'float64(float64, float64)'])\n",
    "def my_ufunc(x, y):\n",
    "    return np.abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayKWy9pAdUA9",
    "outputId": "a3e230ea-3a03-4550-a81d-546a08fe4a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1.0, 10.0, dtype='f8')\n",
    "b = np.arange(1.1, 10.1, dtype='f8')\n",
    "print(my_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv8svWxOdTM5",
    "outputId": "b7e91d81-dcf1-4273-b178-f1764873c8d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1, 10, dtype='i4')\n",
    "b = np.arange(2, 11, dtype='i4')\n",
    "print(my_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpRPsiCXcsK6"
   },
   "source": [
    "#### 4.4.1.4. Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epwq91XHiD4w"
   },
   "source": [
    "Create two vectorized functions: `my_cpu_ufunc` and `my_gpu_func`. Both receive two arrays `x` and `y` as input parameters.\n",
    "\n",
    "Make `my_cpu_ufunc` and `my_gpu_ufunc` running in CPU and GPU, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_Sp0xn6cvx8"
   },
   "source": [
    "#### 4.4.1.5. Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urtaqyTJimPL"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jd_Zpz_WiuAj"
   },
   "outputs": [],
   "source": [
    "# generating data\n",
    "a = np.arange(1.0, 10.0)\n",
    "b = np.ones(shape=a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P5XrUesxia2a"
   },
   "outputs": [],
   "source": [
    "# add the decorartor here!\n",
    "def my_cpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlBl6-rDieyD"
   },
   "outputs": [],
   "source": [
    "# add the decorartor here!\n",
    "def my_gpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUv6LEtxjFwo"
   },
   "source": [
    "Try them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_59neYsio57",
    "outputId": "10d63479-aad0-46ec-c960-99ff02602bdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 µs, sys: 4 µs, total: 29 µs\n",
      "Wall time: 33.4 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_cpu_ufunc(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQz5MAwXi36k",
    "outputId": "7f7e599b-e1cf-4c44-8259-4d6ce3e297df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 ms, sys: 33 µs, total: 4.37 ms\n",
      "Wall time: 4.51 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_gpu_ufunc(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voMEhB-_jsjR"
   },
   "source": [
    "How was the performance of CPU vs GPU vectorization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1inNsKNNR8u"
   },
   "source": [
    "#### 4.4.1.5 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9BouUkTgv3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XBXxiGCc7ME"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWF4kcbHc5sx"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='cpu')\n",
    "def my_cpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PSoyCGE7giQC"
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='cuda')\n",
    "def my_gpu_ufunc(x, y):\n",
    "    return abs(x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz-cy60kc-4N"
   },
   "outputs": [],
   "source": [
    "a = np.arange(1.0, 10.0)\n",
    "b = np.ones(shape=a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKVIoYRmdAlM",
    "outputId": "6440148b-731c-4cf0-805d-41c3402c290c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Calls compiled version of my_ufunc for each element of a and b\n",
    "print(my_cpu_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mf5UQf9Pf9r4",
    "outputId": "b850d14a-19a2-43e8-cfb0-4389ce5a766c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Calls compiled version of my_ufunc for each element of a and b\n",
    "print(my_gpu_ufunc(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a81YE7d-NWjR"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ckygt4ljbFu"
   },
   "source": [
    "## 4.4.2.  GPU's Device functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMSAbJ-BNgtF"
   },
   "source": [
    "### 4.4.2.1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9drHZ19Nlnl"
   },
   "source": [
    "Remember the CUDA program flow? We can have control of the data transfering of our data from/to GPU with GPU's device functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qNuapQWN95X"
   },
   "source": [
    "<img src=\"imgs/slides_d2/071.PNG\" width=\"70%\" height=\"70%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFRV5zL2N-dK"
   },
   "source": [
    "These functions are compiled functoins executed on GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wqL_dwAZMlJ"
   },
   "source": [
    "### 4.4.2.2. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdUf39j8Q1im"
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8p-PAufPQxlN"
   },
   "outputs": [],
   "source": [
    "@vectorize(['int16(int16, int16)'], target='cuda')\n",
    "def a_device_function(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXLXEjs8RnJG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1f9OVMDRP-j",
    "outputId": "1de3a50f-efef-49db-aca3-3075311e8623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[2 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "n = 10_000\n",
    "x = np.ones(shape=n, dtype=np.int16)\n",
    "y = x*2\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ymQ9PuVERFu7"
   },
   "outputs": [],
   "source": [
    "# transfer inputs to the gpu\n",
    "x_gpu = cuda.to_device(x)\n",
    "y_gpu = cuda.to_device(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBiZYEFPQyWC"
   },
   "outputs": [],
   "source": [
    "# creating out array on GPU\n",
    "z_gpu = cuda.device_array(shape=(n,), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iO7qL47QyqW",
    "outputId": "7a1dda42-dd59-4c5f-faf9-0f9a728593f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devicearray.DeviceNDArray at 0x7f94f73de450>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_device_function(x_gpu, y_gpu, out=z_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmPlYh1GR2cF"
   },
   "outputs": [],
   "source": [
    "z = z_gpu.copy_to_host()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3nw4wWXR5l0",
    "outputId": "c9b5ab6e-0f6c-435e-cf51-d8b7019e7503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeJ3q-CIJo3x"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJ7mgYBMhRMW"
   },
   "source": [
    "# Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgfP-b7olP7Z"
   },
   "source": [
    "#### Installing Numba + CUDA on Google Colab!\n",
    "\n",
    "`(src=https://thedatafrog.com/en/articles/boost-python-gpu/)`\n",
    "\n",
    "We need to add two libraries: `libdevice` and `libnvvm.so`.\n",
    "\n",
    "In order to find it we nee to run:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud875YEtJVqE",
    "outputId": "b8298142-a374-4c99-b2e6-274cdccbf96e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\n",
      "/usr/local/cuda-11.0/nvvm/libdevice\n",
      "/usr/local/cuda-11.1/nvvm/libdevice\n",
      "/usr/local/cuda-10.0/nvvm/libdevice\n",
      "/usr/local/cuda-10.1/nvvm/libdevice\n",
      "find: ‘/proc/34/task/34/net’: Invalid argument\n",
      "find: ‘/proc/34/net’: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libdevice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ApKCGqXUJVss",
    "outputId": "99401a31-7e3e-4d53-e26c-40feae19e5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-11.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-11.1/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\n",
      "/usr/local/cuda-10.1/nvvm/lib64/libnvvm.so\n",
      "find: ‘/proc/34/task/34/net’: Invalid argument\n",
      "find: ‘/proc/34/net’: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "!find / -iname 'libnvvm.so'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AgPcnUWlZhY"
   },
   "source": [
    "Finally, execute the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D4EYfDnOJVx6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/lib/python3.7/dist-packages/jaxlib/cuda/nvvm/libdevice\"\n",
    "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvgC4XWO1zH3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JZcx5jK0st3"
   },
   "source": [
    "----\n",
    "\n",
    "Day #2 of the summer course \"_Introduction to High-Performance Computing in Python for Scientists!_\". \n",
    "\n",
    "\n",
    "[Goethe Research Academy for Early Career Researchers (GRADE)](https://www.goethe-university-frankfurt.de/), Goethe University Frankfurt, Germany. June 2022.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TCR-HPC-D2_github  -  Introduction to HPC and applications in Python.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
